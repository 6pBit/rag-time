{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Retrieval-Augmented Generation (RAG) with Azure OpenAI and Azure AI Search\n",
    "\n",
    "This notebook demonstrates how to set up and use Azure OpenAI and Azure AI Search to retrieve relevant documents using vector search and generate responses using a Retrieval-Augmented Generation (RAG) approach.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running the notebook, ensure you have the following: \n",
    "\n",
    "- [Fork](https://github.com/microsoft/rag-time/fork) the repository and clone it to your local machine by following the script below:\n",
    "\n",
    "    ```bash\n",
    "    git clone https://github.com/your-org/rag-time.git\n",
    "    cd rag-time\n",
    "    ```\n",
    "\n",
    "- An [Azure account](https://portal.azure.com) with proper permissions to access the following services:\n",
    "    - An **Azure OpenAI** service with an active deployment of a **chat model** and an **embedding model**.\n",
    "    - An **Azure AI Search** service with an index that contains vectorized text data. Follow the instructions in the [Quickstart](https://learn.microsoft.com/en-us/azure/search/search-get-started-portal-import-vectors?tabs=sample-data-storage%2Cmodel-aoai%2Cconnect-data-storage) to index the documents in [data](./../../data/) folder. \n",
    "- Install Python 3.8 or later from [python.org](https://python.org).\n",
    "\n",
    "## Steps to Use the Notebook\n",
    "\n",
    "### 1. Install Required Libraries\n",
    "\n",
    "Run the first code cell to install the required Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install azure-search-documents \n",
    "!python3 -m pip install azure-identity\n",
    "!python3 -m pip install openai\n",
    "!python3 -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Up Environment Variables\n",
    "\n",
    "To store credentials securely, rename `.env.sample` file to `.env` in the same directory as the notebook and update the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT=\"https://aoai-fastai-rag.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME=\"gpt-4o-mini\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME=\"text-embedding-3-large\"\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT=\"https://aisearch-fastai-rag.search.windows.net\"\n",
    "AZURE_SEARCH_INDEX_NAME=\"sopravector\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "AZURE_SEARCH_ADMIN_KEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up, the notebook will automatically load these values using dotenv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setup API Clients\n",
    "\n",
    "This section initializes API clients for Azure OpenAI and Azure AI Search. Ensure the necessary credentials are properly configured before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "import dotenv\n",
    "from azure.search.documents.models import VectorizedQuery, VectorizableTextQuery\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "# Load Azure OpenAI environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "\n",
    "# Load Azure Search environment variables\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "# ðŸ”¹ Initialize Azure OpenAI Client (API Key or Managed Identity)\n",
    "if AZURE_OPENAI_API_KEY:\n",
    "    openai_client = AzureOpenAI(\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=\"2024-10-21\"\n",
    "    )\n",
    "else:\n",
    "    azure_credential = DefaultAzureCredential()\n",
    "    token_provider = get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "    openai_client = AzureOpenAI(\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=\"2024-10-21\"\n",
    "    )\n",
    "\n",
    "# ðŸ”¹ Initialize Azure AI Search Client (API Key or Managed Identity)\n",
    "if AZURE_SEARCH_ADMIN_KEY:\n",
    "    search_client = SearchClient(\n",
    "        endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY)\n",
    "    )\n",
    "else:\n",
    "    azure_credential = DefaultAzureCredential()\n",
    "    search_client = SearchClient(\n",
    "        endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "        credential=azure_credential\n",
    "    )\n",
    "\n",
    "def get_embedding(text):\n",
    "    return openai_client.embeddings.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME\"),\n",
    "        input=text\n",
    "    ).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare a question\n",
    "\n",
    "Define a sample question and convert it into an embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Fortell meg om foreldrepermisjon\"\n",
    "#print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "#print(os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME\"))\n",
    "user_question_vector = get_embedding(user_question)\n",
    "print(\"Text embedding\")\n",
    "print(user_question_vector)\n",
    "print(len(user_question_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieve matching documents\n",
    "\n",
    "Perform a vector search in Azure AI Search to retrieve relevant document chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search_client.search(\n",
    "    None,\n",
    "    top=3,\n",
    "    vector_queries=[\n",
    "        VectorizableTextQuery(\n",
    "            text=user_question, k_nearest_neighbors=3, fields=\"text_vector\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print Results\n",
    "for result in search_results:\n",
    "     print(\"Chunk ID:\", result[\"chunk_id\"])\n",
    "     print(\"Title:\", result[\"title\"])\n",
    "     print(\"Text:\", result[\"chunk\"])\n",
    "     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. RAG TIME! Generate a Response\n",
    "\n",
    "Using the retrieved documents, construct a **system prompt** and generate a response with Azure OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's collect the context from search results\n",
    "context = \"\"\n",
    "for result in search_results:\n",
    "    context += result[\"chunk\"] + \"\\n\\n\"\n",
    "\n",
    "SYSTEM_MESSAGE = f\"\"\"\n",
    "Du er en AI Assistant som har innsikt i Sopra Steria sin personalhÃ¥ndbok.\n",
    "VÃ¦r kortfattet og presis i svarene dine, bruk kun informasjon fra hÃ¥ndboken.\n",
    "Hvis ikke du finner informasjon i hÃ¥ndboken, si at du ikke vet svaret.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "USER_MESSAGE = user_question\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\"),\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "1. **Environment Variables Not Loaded:** Ensure you have correctly set the `.env` file or manually export them in your terminal before running the notebook.\n",
    "1. **Authentication Issues:** If using Managed Identity, make sure your Azure identity has proper role assignments.\n",
    "1. **Search Results Are Empty:** Ensure your Azure AI Search index contains vectorized data.\n",
    "1. **OpenAI API Errors:** Verify your deployment name and API key.\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrates a **vector-based RAG pipeline** using Azure OpenAI and Azure AI Search. It retrieves relevant documents using vector search and generates responses using GPT-based chat completions. The approach improves the accuracy of AI responses by grounding them in real data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
